# Elastic Load Balancing & Auto Scaling Groups

## Scaling and Availability
Scale => Application can handle greater loads by adapting

## Scalability - Two kinds:

### Vertical scalability - Scale up / down
- Increase the size of the instance
For example: Scaling a EC2 instance from t2.micro to t2.large
 - Very common for non-distributed systems, such as a database
 - There's a limit (hardware) to how much you can scale

### Horizontal scalability (Elasticity) - Scale out / in (less)
- Increase number of instances for you applications
- Horizontal scaling implies distributed systems
- Very common for web applications

Ex: Auto Scaling Group, Load Balancer

## High availability
- High availability usually goes hand-in-hand with horizontal scaling
- High availability means you are ruunning application in at least two availability zones
- The goal of high availability is to survive a data center loss (disaster / power outage / earthquake)

Running multiple instances on different availability zones managed by Auto Scaling Group
- Load Balancer in multiple AZ

### Definitions
Scalability: Accomodate large load by scaling up (stronger hardware) or adding nodes (scaling out)
Elasticity: Once a system is scablable, there will be some form of auto-scaling. System scales as a function of the load it is receiving.
Agility: Not related to scalability - distractor. Agile concept.

# Elastic Load Balancer
Server that forward internet traffic to multiple servers downstream (EC2 instances)
- This is what we publicly expose to our users
- BEhind load balancers we will have multiple EC2 instances.

Balances the request load across multiple EC2 instances, so it allows us to scale our backend better.

Why use load balancer?
- Spread load across multiple downstream instances.
- Expose single point of access.
- Regular health checks on instances: Seamlessly handle failures of downstream instances (If an instance is failing Load Balancer wont direct traffic to it)
- Provide SSL termination (HTTPS)
- High availability accross zones

ELB
- Managed load balancer. No provisioning od servers
- AWS takes cares of updates and ensures high availability
- It's cheaper to set up own load balancer, but more effort

## 4 Types of load balancers in AWS

1. Application Load Balancer (Http and Https only, gRPC) - Layer 7
- HTTP routeing features
- Static DNS (static url)
- routes traffic to downstream targets

2. Network Load Balancer (Ultra high performance, allows for TCP) - Layer 4
- TCP and UDP protocol
- High performance: millions of requests per second
- Static Ip through Elastic IP ()
- Same architecture as App Load Balancer, routes traffic to downstream targets

3. Gateway Load Balancer - Layer 3
- GENEVE protocol on IP packages (Layer 3)
- Route traffic to firewalls you manage on EC2 instances
- Intrusion detenction

Architecture: 
- GLB first routes traffic to a 3rd party security virtual applicances so that you can perform checks and firewalls
- Then the virtual applicances send traffic back to GLB
- Finally GLB sends traffic to application
Allowsto inspect the Ip packages first

4. Classic Load Balancer (Retired on 2023) - Layer 4 & 7

# Hands on notes

The exercise consists in creating two Ec2 instances that serve a slightly different hello world. We then create a Load Balancer, attach a security group that alows http traffic, and a target group with both EC2 instances. Once everything is hooked up we can put the DNS address of the load balancer and reload repeatedly. We will see how the load balancer servers both the applications. If we stop an instance, it will stop serving that one until restarted.

# Target Group
A target group determines where the action that reached the load balancer is targeted to. In the demo case above, it was two EC2 instances.
The security group, on the other handles the fiewwall that determies traffic in and out of the load balancer. Each open port in the Security Group inbound shoud have a Target Group attached, as the receipient of traffic.

For example, in Kurku the Security Group receives traffic on ports 80 and 443. Both point to the same Target Group that has the (1) instance of Kurku. Then, if  wanted to add more EC2 instances to Kurku, I shoud add them to the Target Group and the load balancer would handle the traffic.

# Auto Scaling Groups (ASG) (Scale in our out - horizontal)

Applications can have intermitent traffic. 

With ASG we can:
 - Scale in or out (Add or remove EC2 instances)
 - Determine the minimum or maximum amount of EC2 instances running at a given time.
 - Automatically register instances to a load balancer
 - Replace unhealthy instances.
 - Cost Saving


## ASG strategies

- Scaling manually (change capactiy manually)
- Dynamic scaling (Respond to changing demand)
    - Simple / Step scaling: (For example, when capacity of running instance >70%, add 2 ec2 instances). Other rule for removal
    - Target tracking scaling: For example, avarage of all CPUs at 40%
    - Scheduled scaling: Scale at a specific time with advance knowledge on when its happening
    - Predictive Scaling: AI predicted scaling from previous traffic

## ASG Hands on notes
- Create an Autoscaling group
- Create a Launch template => AMI 

Homework before moving on to next section:
Make Kurku ASG
1) Make AMI from current state of Kurku Instance. Use that AMI for ASG Lauch Template
2) Follow Udemy hands on to set up ASG
3) Test

Follow tutorial: https://medium.com/@harshamw/a-practical-implementation-of-auto-scaling-on-aws-8a03b991c541



