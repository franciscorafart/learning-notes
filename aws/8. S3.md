# S3

## Use cases
- backup and storage
- Disaster recovery
- Archive
- Application hosting
- Media hosting
- Software delivery
- Static website

## S3 Buckets
- Amazon stores Objects (files) on Buckets (Directories)
- Buckets must have globally unique name (across all regions and all accounts)
- Buckets are created on a region, but S3 looks like a global service (buckets available in all regions)
- Naming convention: No uppercase, no underscore, 3-63 chars long, not an ip, start with lowercase or number

## Objects (files)
- Objects have a key
- The key is the FULL path to the file (Prefix + object name)
    For example: `s3://my-bucket/my_file.txt`
- No concept of directories, allthough UI makes it look like it
- Just jeys with long names that contain slashes
- Values are content of the body
- Max object size: 5TB
- If uploading big file (>5GB) use `multi-part upload`
- Metadata: list of text key / value pairs
- Tags (Unicode key / value pair) - useful for security / lifecycle
- Version ID
- Objects have a public URL and a signed Url.
    - When you hit the Open button, you see the file because it takes you to a signed URL that has your credentials encoded
    - When accessing the public url, the access can be denied

## Security

1. User-based (IAM policy)
IAM policies => Which API calls are authorized for a specific IAM user

2. Resource-Based security (Bucket Policy)
- Bucket-wide rules from the S3 console. This is where we make an S3 bucket public (most common)
- Object Access Control list (ACL) => Finer grained access policies (can be disabled)
- Bucket Access Control List (ACL)=> less common (can be disabled)

IAM can access bucket if:
- IAM permission allows it
OR
- Resource policy allows it
AND
- There isn't any explicit DENY access

3. Encryption
S3 content can be encrypted for further security

## S3 Bucket Policies
- JSON based policies
    - "Resource" specifies the resources affected by the policy
    - "Effect" specifies what actions we Allow or Deny
    - "Action" specifies what action is allowed (or denied)

We can use an S3 policy to grant public access to a bucket, grant access to another account, or encrypt file on upload. 

Examples:

S3 access permissions to an IAM user with an IAM policy.
S3 access to a EC2 instance, use an Ec2 instance role with the corresponding permissions.
Advanced: For cross account access, use Bucket Policy.

### Bucket settings for block public access
These were created to avoid company data leaks.

If your bucket should never be public, allways leave this ON
Can be set at the account level too if no S3 buckets should be public.


```
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "PublicReadGetObject",
			"Effect": "Allow",
			"Principal": "*",
			"Action": "s3:GetObject",
			"Resource": "arn:aws:s3:::francisco-test/*"
		}
	]
}
```

`"Resource": ["<arn_resource>/*"]` => `/*` says every element in the specified bucket is accessible. Becauase GetObject action applies to individual objects in the bucket.
`"Principal": "*"` => Anyone can access

### Static websites
S3 can host static websites.

For static sites, disable `Block public access` and add a Read Policy for the bucket.

#### Hands on static websites
1. Enable Static Website on properties
2. Specify entry point (index.html)

## S3 versioning
- You can version files on S3
It needs to be enabled at the bucket level

- What it does?
If we re-upload that file, it will create a version of it instead of deleting the old one.

- Why?
It is best practice to version buckets:
    - Protects against unintentional deleted (Marks the files to be deleted before deleting them)
    - Easy to roll back
    - Any file existing prior to versioning will have version = null
    - Suspending versioning doesn't delete previous versioning.

With the `Show Versions` toggle you can see the versions of the different files